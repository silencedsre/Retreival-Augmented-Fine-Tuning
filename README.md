## Retreival Augmented Fine-Tuning(RAFT)

**RAFT** is the new way to teach LLMs to be better at RAG

**"Retrieval-Augmented Fine-Tuning"** combines the advantages of Retrieval-Augmented Generation and Fine-Tuning to improve domain adaptation.


**Paper link**: https://arxiv.org/pdf/2403.10131


* Refer to `RAFT Dataset Generation.ipynb` for generating required dataset for finetuning

* Refer to `RAFT Model Finetune and Inference.ipynb` for finetuning and inference

All of the code samples are tested on Google Colab.

**References**:
1. https://github.com/ShishirPatil/gorilla/tree/main/raft
2. https://github.com/run-llama/llama_index/blob/main/llama-index-packs/llama-index-packs-raft-dataset/examples/raft_dataset.ipynb
3. https://github.com/NielsRogge/Transformers-Tutorials/blob/master/Mistral/Supervised_fine_tuning_(SFT)_of_an_LLM_using_Hugging_Face_tooling.ipynb